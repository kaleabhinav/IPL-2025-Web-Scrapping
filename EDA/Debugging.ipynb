{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f65e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.iplt20.com/match/2025/1838\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bef8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09ccd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06452895",
   "metadata": {},
   "outputs": [],
   "source": [
    "inning_tabs = driver.find_elements(By.CSS_SELECTOR, \"a.ap-inner-tb-click\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d02d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in inning_tabs:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8c3ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(inning_tabs) < 2:\n",
    "    raise ValueError(\"Less than two innings tabs found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5885d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_tab = inning_tabs[0]\n",
    "first_team = first_tab.text.strip()\n",
    "first_tab.click()\n",
    "time.sleep(2)\n",
    "first_inning_soup = BeautifulSoup(driver.page_source, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54045e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_tab = inning_tabs[1]\n",
    "second_team = second_tab.text.strip()\n",
    "second_tab.click()\n",
    "time.sleep(2)\n",
    "second_inning_soup = BeautifulSoup(driver.page_source, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3b43af",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_inning_soup, second_inning_soup, whos_first_inning, whos_second_inning = first_inning_soup, second_inning_soup, first_team, second_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e794148",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_metadata(soup):\n",
    "    \"\"\"\n",
    "    The function provides metadata of the match up between two teams.\n",
    "    Input : Provide the soup of the innings html data.\n",
    "    Ouput : Gives out a array of [Match Number, Venue, Date, Time].\n",
    "    \"\"\"\n",
    "    l = []\n",
    "    match_number = soup.find(class_ = \"matchOrder mob-hide ng-binding ng-scope\").text \n",
    "    l.append(match_number)\n",
    "    \n",
    "    for i in soup.find(class_ = \"ap-match-place col-100 floatLft textCenter re ng-scope\").find_all('span'):\n",
    "        l.append(i.text)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e59197",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_metadata = get_match_metadata(first_inning_soup)\n",
    "match_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49c1322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ball_by_ball_commentary(soup):\n",
    "    # ball_wrapper = soup.find_all('div', class_ = ['ballWrapper ng-scope','cmdOver mcBall mcBall mcBall mcBall mcBall mcBall'])\n",
    "    ball_wrapper = soup.select('div.ballWrapper.ng-scope')\n",
    "    ball_wrapper = ball_wrapper[1:]\n",
    "    \n",
    "    # To Store the scrapped data\n",
    "    l = []\n",
    "\n",
    "    for i in ball_wrapper:\n",
    "        if i.p.contents[0].strip() != '':\n",
    "\n",
    "            # Which ball of the over is this\n",
    "            ball_number = i.p.contents[0].strip()\n",
    "\n",
    "            # Event happened on this ball\n",
    "            event_on_that_ball = i.find('i').text.strip()\n",
    "\n",
    "            # bowler vs batter info\n",
    "            bowling_info_tag = i.find('div', class_='commentaryStartText')\n",
    "            bowling_info = bowling_info_tag.get_text(strip=True) if bowling_info_tag else None\n",
    "\n",
    "            # detailed commentary\n",
    "            commentary_tag = i.find('div', class_='commentaryText')\n",
    "            commentary = commentary_tag.get_text(strip=True) if commentary_tag else None\n",
    "\n",
    "            l.append({\n",
    "                'ball': ball_number,\n",
    "                'event': event_on_that_ball,\n",
    "                'bowling_info': bowling_info,\n",
    "                'commentary': commentary,\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(l)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95509139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = get_ball_by_ball_commentary(first_inning_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddd831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = get_ball_by_ball_commentary(first_inning_soup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e9726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177e30d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956d27f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_soups(url):\n",
    "\n",
    "    options = Options()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "    \n",
    "    driver = webdriver.Chrome(options = options)\n",
    "    driver.get(url)\n",
    "\n",
    "    # Use explicit wait instead of sleep\n",
    "    wait = WebDriverWait(driver, 15)\n",
    "    wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"a.ap-inner-tb-click\")))\n",
    "\n",
    "    inning_tabs = driver.find_elements(By.CSS_SELECTOR, \"a.ap-inner-tb-click\")\n",
    "\n",
    "    if len(inning_tabs) < 2:\n",
    "        raise ValueError(\"Less than two innings tabs found.\")\n",
    "\n",
    "    # First innings\n",
    "    first_tab = inning_tabs[0]\n",
    "    first_team = first_tab.text.strip()\n",
    "    first_tab.click()\n",
    "    time.sleep(2)\n",
    "    first_inning_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    # Second innings\n",
    "    second_tab = inning_tabs[1]\n",
    "    second_team = second_tab.text.strip()\n",
    "    second_tab.click()\n",
    "    time.sleep(2)\n",
    "    second_inning_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return first_inning_soup, second_inning_soup, first_team, second_team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a37d0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = get_match_soups(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388ecd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def get_match_soups(url):\n",
    "    options = Options()\n",
    "    # Commented out headless mode for debugging\n",
    "    # options.add_argument('--headless')\n",
    "    options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get(url)\n",
    "\n",
    "    # Debug step: Print first 1000 characters of the page source for inspection\n",
    "    print(driver.page_source[:1000])  # Print first 1000 chars\n",
    "    driver.save_screenshot(\"debug.png\")  # Save a screenshot for inspection\n",
    "\n",
    "    # Wait for an earlier element (before tabs) to confirm the page is loaded\n",
    "    wait = WebDriverWait(driver, 15)\n",
    "    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.some-container-or-tab-wrapper\")))  # Replace with a more reliable element\n",
    "\n",
    "    # Now, wait for the innings tabs\n",
    "    inning_tabs = wait.until(\n",
    "        EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"a.ap-inner-tb-click\"))\n",
    "    )\n",
    "\n",
    "    if len(inning_tabs) < 2:\n",
    "        raise ValueError(\"Less than two innings tabs found.\")\n",
    "\n",
    "    # First innings\n",
    "    first_tab = inning_tabs[0]\n",
    "    first_team = first_tab.text.strip()\n",
    "    first_tab.click()\n",
    "    time.sleep(2)  # You can replace this with another WebDriverWait if needed\n",
    "    first_inning_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    # Re-find the inning tabs after page update (to avoid stale elements)\n",
    "    inning_tabs = driver.find_elements(By.CSS_SELECTOR, \"a.ap-inner-tb-click\")\n",
    "\n",
    "    # Second innings\n",
    "    second_tab = inning_tabs[1]\n",
    "    second_team = second_tab.text.strip()\n",
    "    second_tab.click()\n",
    "    time.sleep(2)  # Again, consider WebDriverWait here\n",
    "    second_inning_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return first_inning_soup, second_inning_soup, first_team, second_team\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9687112",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = get_match_soups(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e7e8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def get_match_soups(url):\n",
    "    options = Options()\n",
    "    # Comment out headless mode for debugging\n",
    "    # options.add_argument('--headless')\n",
    "    options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get(url)\n",
    "\n",
    "    # Debug step: Print first 1000 characters of the page source for inspection\n",
    "    print(driver.page_source[:1000])  # Print first 1000 chars\n",
    "    driver.save_screenshot(\"debug.png\")  # Save a screenshot for inspection\n",
    "\n",
    "    # Wait for a common container element (replace with an actual container)\n",
    "    wait = WebDriverWait(driver, 15)\n",
    "    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.some-container-or-tab-wrapper\")))  # Replace with a real selector\n",
    "\n",
    "    # Now, wait for the innings tabs\n",
    "    inning_tabs = wait.until(\n",
    "        EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"a.ap-inner-tb-click\"))\n",
    "    )\n",
    "\n",
    "    if len(inning_tabs) < 2:\n",
    "        raise ValueError(\"Less than two innings tabs found.\")\n",
    "\n",
    "    # First innings\n",
    "    first_tab = inning_tabs[0]\n",
    "    first_team = first_tab.text.strip()\n",
    "    first_tab.click()\n",
    "    time.sleep(2)  # Replace with WebDriverWait if needed\n",
    "    first_inning_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    # Re-find the inning tabs after the first tab click (avoid stale reference)\n",
    "    inning_tabs = driver.find_elements(By.CSS_SELECTOR, \"a.ap-inner-tb-click\")\n",
    "\n",
    "    # Second innings\n",
    "    second_tab = inning_tabs[1]\n",
    "    second_team = second_tab.text.strip()\n",
    "    second_tab.click()\n",
    "    time.sleep(2)  # Again, consider WebDriverWait here\n",
    "    second_inning_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return first_inning_soup, second_inning_soup, first_team, second_team\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea42ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = get_match_soups(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebc7eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def get_match_soups(url):\n",
    "    options = Options()\n",
    "    # options.add_argument('--headless')  # Uncomment for headless mode\n",
    "    options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait until the page has fully loaded (adjust for visible element in the header)\n",
    "    wait = WebDriverWait(driver, 15)\n",
    "    wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"div.main-header\")))  # Replace with an actual element you know will be on page\n",
    "\n",
    "    # Debug: Print the first 1000 chars of page source to verify the content\n",
    "    print(driver.page_source[:1000])\n",
    "    driver.save_screenshot(\"debug.png\")  # Screenshot for visual confirmation\n",
    "\n",
    "    # Wait for the innings tabs to be clickable\n",
    "    inning_tabs = wait.until(\n",
    "        EC.element_to_be_clickable((By.CSS_SELECTOR, \"a.ap-inner-tb-click\"))\n",
    "    )\n",
    "\n",
    "    # Check that we found enough tabs\n",
    "    if len(inning_tabs) < 2:\n",
    "        raise ValueError(\"Less than two innings tabs found.\")\n",
    "\n",
    "    # First innings\n",
    "    first_tab = inning_tabs[0]\n",
    "    first_team = first_tab.text.strip()\n",
    "    first_tab.click()\n",
    "    time.sleep(2)  # Wait for the content to load\n",
    "\n",
    "    # Parse the first innings\n",
    "    first_inning_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    # Re-fetch the tabs after page change to avoid stale reference\n",
    "    inning_tabs = driver.find_elements(By.CSS_SELECTOR, \"a.ap-inner-tb-click\")\n",
    "\n",
    "    # Second innings\n",
    "    second_tab = inning_tabs[1]\n",
    "    second_team = second_tab.text.strip()\n",
    "    second_tab.click()\n",
    "    time.sleep(2)  # Wait for the content to load\n",
    "\n",
    "    # Parse the second innings\n",
    "    second_inning_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return first_inning_soup, second_inning_soup, first_team, second_team\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e46e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = get_match_soups(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584c57c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1195a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# url = \"your_url_here\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Print the status code to check if you are being blocked\n",
    "print(f\"HTTP Response Code: {response.status_code}\")\n",
    "\n",
    "if response.status_code == 403:\n",
    "    print(\"Access Forbidden - Blocked\")\n",
    "elif response.status_code == 429:\n",
    "    print(\"Rate-limited - Too many requests\")\n",
    "elif response.status_code == 200:\n",
    "    print(\"Page Loaded Successfully!\")\n",
    "else:\n",
    "    print(\"Unexpected response code:\", response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bc5b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "def get_match_soups(url):\n",
    "    options = Options()\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")  # Avoid detection\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\")  # Mimic a real browser\n",
    "\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.get(url)\n",
    "\n",
    "    # Wait for the innings tabs to appear\n",
    "    wait = WebDriverWait(driver, 15)\n",
    "    inning_tabs = wait.until(EC.presence_of_all_elements_located((By.CSS_SELECTOR, \"a.ap-inner-tb-click\")))\n",
    "\n",
    "    # Print the number of tabs found for verification\n",
    "    print(f\"Found {len(inning_tabs)} innings tabs.\")\n",
    "\n",
    "    # Continue with the rest of the scraping as usual\n",
    "    if len(inning_tabs) < 2:\n",
    "        raise ValueError(\"Less than two innings tabs found.\")\n",
    "    \n",
    "    # First innings\n",
    "    first_tab = inning_tabs[0]\n",
    "    first_team = first_tab.text.strip()\n",
    "    first_tab.click()\n",
    "    time.sleep(2)\n",
    "    first_inning_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    # Second innings\n",
    "    second_tab = inning_tabs[1]\n",
    "    second_team = second_tab.text.strip()\n",
    "    second_tab.click()\n",
    "    time.sleep(2)\n",
    "    second_inning_soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    return first_inning_soup, second_inning_soup, first_team, second_team\n",
    "\n",
    "# Run the function\n",
    "# url = \"your_url_here\"\n",
    "first_inning_soup, second_inning_soup, first_team, second_team = get_match_soups(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df522c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipl-scrapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
